{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "season-week-kernel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMwX9UI47YCSbTXHNYIpf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Serena-Wang/Anagrams/blob/master/season_week_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoiI0UCfjo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "3e282996-13a6-4e6a-c097-adae19da3c03"
      },
      "source": [
        "!git clone https://github.com/tensorflow/probability.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'probability' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ_T5cGif2qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/probability')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "751IhCK6gm9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e21a66bd-4462-459a-ca68-60a5ff072a5a"
      },
      "source": [
        "cd /content/probability/tensorflow_probability"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/probability/tensorflow_probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSvsXAnhFvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1t_aM7BgBw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import probability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKUhonOMbuzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from tensorflow_probability.python.internal import assert_util\n",
        "from tensorflow_probability.python.internal import tensor_util\n",
        "from tensorflow_probability.python.math.psd_kernels.internal import util\n",
        "from tensorflow_probability.python.math.psd_kernels.positive_semidefinite_kernel import PositiveSemidefiniteKernel\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az48uq5KcrZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__all__ = ['season_week_kernel']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq2sCy8tja08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class season_week_kernel(PositiveSemidefiniteKernel):\n",
        "  \"\"\"The season_week_kernel kernel.\n",
        "  Sometimes called the \"squared exponential\", \"Gaussian\" or \"radial basis\n",
        "  function\", this kernel function has the form\n",
        "    ```none\n",
        "    k(x, y) = amplitude**2 * exp(-||x - y||**2 / (2 * length_scale**2))\n",
        "    ```\n",
        "  where the double-bars represent vector length (ie, Euclidean, or L2 norm).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               amplitude_k=None,\n",
        "               length_scale_k=None,\n",
        "               amplitude_ks=None,\n",
        "               length_scale_ks=None,\n",
        "               feature_ndims=1,\n",
        "               validate_args=False,\n",
        "               name='season_week_kernel'):\n",
        "    \"\"\"Construct an ExponentiatedQuadratic kernel instance.\n",
        "    Args:\n",
        "      amplitude: floating point `Tensor` that controls the maximum value\n",
        "        of the kernel. Must be broadcastable with `length_scale` and inputs to\n",
        "        `apply` and `matrix` methods. Must be greater than zero. A value of\n",
        "        `None` is treated like 1.\n",
        "        Default value: None\n",
        "      length_scale: floating point `Tensor` that controls how sharp or wide the\n",
        "        kernel shape is. This provides a characteristic \"unit\" of length against\n",
        "        which `||x - y||` can be compared for scale. Must be broadcastable with\n",
        "        `amplitude` and inputs to `apply` and `matrix` methods. A value of\n",
        "        `None` is treated like 1.\n",
        "        Default value: None\n",
        "      feature_ndims: Python `int` number of rightmost dims to include in the\n",
        "        squared difference norm in the exponential.\n",
        "      validate_args: If `True`, parameters are checked for validity despite\n",
        "        possibly degrading runtime performance\n",
        "      name: Python `str` name prefixed to Ops created by this class.\n",
        "    \"\"\"\n",
        "    parameters = dict(locals())\n",
        "    with tf.name_scope(name):\n",
        "      dtype = util.maybe_get_common_dtype(\n",
        "          [amplitude_k, length_scale_k,amplitude_ks, length_scale_ks])\n",
        "      self._amplitude_k = tensor_util.convert_nonref_to_tensor(\n",
        "          amplitude_k, name='amplitude', dtype=dtype)\n",
        "      self._length_scale_k = tensor_util.convert_nonref_to_tensor(\n",
        "          length_scale_k, name='length_scale', dtype=dtype)\n",
        "      self._amplitude_ks = tensor_util.convert_nonref_to_tensor(\n",
        "          amplitude_ks, name='amplitude', dtype=dtype)\n",
        "      self._length_scale_ks = tensor_util.convert_nonref_to_tensor(\n",
        "          length_scale_ks, name='length_scale', dtype=dtype)\n",
        "      super(ExponentiatedQuadratic, self).__init__(\n",
        "          feature_ndims,\n",
        "          dtype=dtype,\n",
        "          name=name,\n",
        "          validate_args=validate_args,\n",
        "          parameters=parameters)\n",
        "\n",
        "  @property\n",
        "  def amplitude(self):\n",
        "    \"\"\"Amplitude parameter.\"\"\"\n",
        "    return self._amplitude_k,self._amplitude_ks\n",
        "\n",
        "  @property\n",
        "  def length_scale(self):\n",
        "    \"\"\"Length scale parameter.\"\"\"\n",
        "    return self.self._length_scale_k,self._length_scale_ks\n",
        "\n",
        "  ####????\n",
        "  ##This property describes the fully broadcast shape of all kernel parameters\n",
        "  def _batch_shape(self):\n",
        "    scalar_shape = tf.TensorShape([])\n",
        "    return tf.broadcast_static_shape(\n",
        "        scalar_shape if self.amplitude is None else self.amplitude.shape,\n",
        "        scalar_shape if self.length_scale is None else self.length_scale.shape)\n",
        "  ####????\n",
        "  def _batch_shape_tensor(self):\n",
        "    return tf.broadcast_dynamic_shape(\n",
        "        [] if self.amplitude is None else tf.shape(self.amplitude),\n",
        "        [] if self.length_scale is None else tf.shape(self.length_scale))\n",
        "\n",
        "  def _apply(self, x1, x2, example_ndims=0):\n",
        "    exponent_k = -0.5 * util.sum_rightmost_ndims_preserving_shape(\n",
        "        tf.math.squared_difference(x1, x2), self.feature_ndims)\n",
        "    if self.length_scale is not None:\n",
        "      length_scale = tf.convert_to_tensor(self.length_scale)\n",
        "      length_scale = util.pad_shape_with_ones(\n",
        "          length_scale, example_ndims)\n",
        "      exponent = exponent / length_scale**2\n",
        "\n",
        "    if self.amplitude is not None:\n",
        "      amplitude = tf.convert_to_tensor(self.amplitude)\n",
        "      amplitude = util.pad_shape_with_ones(amplitude, example_ndims)\n",
        "      exponent = exponent + 2. * tf.math.log(amplitude)\n",
        "\n",
        "    return tf.exp(exponent)\n",
        "\n",
        "  def _parameter_control_dependencies(self, is_init):\n",
        "    if not self.validate_args:\n",
        "      return []\n",
        "    assertions = []\n",
        "    for arg_name, arg in dict(amplitude_k=self.amplitude_k,\n",
        "                              length_scale_k=self.length_scale_k,\n",
        "                              amplitude_ks=self.amplitude_ks,\n",
        "                              length_scale_ks=self.length_scale_ks).items():\n",
        "      if arg is not None and is_init != tensor_util.is_ref(arg):\n",
        "        assertions.append(assert_util.assert_positive(\n",
        "            arg,\n",
        "            message='{} must be positive.'.format(arg_name)))\n",
        "    return assertions"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}