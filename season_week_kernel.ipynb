{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "season-week-kernel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPUz93QIxxWbVLsJP9mm3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Serena-Wang/Anagrams/blob/master/season_week_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoiI0UCfjo8",
        "colab_type": "code",
        "outputId": "2dfe4043-2afa-4843-94a8-e852047c5ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/probability.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'probability'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 31309 (delta 30), reused 26 (delta 1), pack-reused 31251\u001b[K\n",
            "Receiving objects: 100% (31309/31309), 47.84 MiB | 28.60 MiB/s, done.\n",
            "Resolving deltas: 100% (26140/26140), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ_T5cGif2qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/probability')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "751IhCK6gm9S",
        "colab_type": "code",
        "outputId": "35d18c6d-cdc9-45e1-80ef-1278db143bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/probability/tensorflow_probability"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/probability/tensorflow_probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSvsXAnhFvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1t_aM7BgBw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import probability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKUhonOMbuzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "116fb9b0-0509-4222-be3f-e417c6614936"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from tensorflow_probability.python.internal import assert_util\n",
        "from tensorflow_probability.python.internal import tensor_util\n",
        "from tensorflow_probability.python.math.psd_kernels.internal import util\n",
        "from tensorflow_probability.python.math.psd_kernels import exponentiated_quadratic\n",
        "from tensorflow_probability.python.math.psd_kernels.positive_semidefinite_kernel import PositiveSemidefiniteKernel\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az48uq5KcrZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__all__ = ['season_week_kernel']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGzAMP36_OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq2sCy8tja08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class season_week_kernel(PositiveSemidefiniteKernel):\n",
        "  \"\"\"The season_week_kernel kernel.\n",
        "  Sometimes called the \"squared exponential\", \"Gaussian\" or \"radial basis\n",
        "  function\", this kernel function has the form\n",
        "    ```none\n",
        "    k(x, y) = amplitude**2 * exp(-||x - y||**2 / (2 * length_scale**2))\n",
        "    ```\n",
        "  where the double-bars represent vector length (ie, Euclidean, or L2 norm).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               amplitude=None,\n",
        "               length_scale=None,\n",
        "               feature_ndims=1,\n",
        "               validate_args=False,\n",
        "               name='season_week_kernel'):\n",
        "    \"\"\"Construct an ExponentiatedQuadratic kernel instance.\n",
        "    Args:\n",
        "      amplitude: floating point `Tensor` that controls the maximum value\n",
        "        of the kernel. Must be broadcastable with `length_scale` and inputs to\n",
        "        `apply` and `matrix` methods. Must be greater than zero. A value of\n",
        "        `None` is treated like 1.\n",
        "        Default value: None\n",
        "      length_scale: floating point `Tensor` that controls how sharp or wide the\n",
        "        kernel shape is. This provides a characteristic \"unit\" of length against\n",
        "        which `||x - y||` can be compared for scale. Must be broadcastable with\n",
        "        `amplitude` and inputs to `apply` and `matrix` methods. A value of\n",
        "        `None` is treated like 1.\n",
        "        Default value: None\n",
        "      feature_ndims: Python `int` number of rightmost dims to include in the\n",
        "        squared difference norm in the exponential.\n",
        "      validate_args: If `True`, parameters are checked for validity despite\n",
        "        possibly degrading runtime performance\n",
        "      name: Python `str` name prefixed to Ops created by this class.\n",
        "    \"\"\"\n",
        "    parameters = dict(locals())\n",
        "    with tf.name_scope(name):\n",
        "      dtype = util.maybe_get_common_dtype(\n",
        "          [amplitude, length_scale])\n",
        "      self._amplitude = tensor_util.convert_nonref_to_tensor(\n",
        "          amplitude, name='amplitude', dtype=dtype)\n",
        "      self._length_scale = tensor_util.convert_nonref_to_tensor(\n",
        "          length_scale, name='length_scale', dtype=dtype)\n",
        "      \n",
        "      super(ExponentiatedQuadratic, self).__init__(\n",
        "          feature_ndims,\n",
        "          dtype=dtype,\n",
        "          name=name,\n",
        "          validate_args=validate_args,\n",
        "          parameters=parameters)\n",
        "\n",
        "  @property\n",
        "  def amplitude(self):\n",
        "    \"\"\"Amplitude parameter.\"\"\"\n",
        "    return self._amplitude\n",
        "\n",
        "  @property\n",
        "  def length_scale(self):\n",
        "    \"\"\"Length scale parameter.\"\"\"\n",
        "    return self.self._length_scale\n",
        "\n",
        "  ####????\n",
        "  ##This property describes the fully broadcast shape of all kernel parameters\n",
        "  def _batch_shape(self):\n",
        "    scalar_shape = tf.TensorShape([])\n",
        "    return tf.broadcast_static_shape(\n",
        "        scalar_shape if self.amplitude is None else self.amplitude.shape,\n",
        "        scalar_shape if self.length_scale is None else self.length_scale.shape)\n",
        "  ####????\n",
        "  def _batch_shape_tensor(self):\n",
        "    return tf.broadcast_dynamic_shape(\n",
        "        [] if self.amplitude is None else tf.shape(self.amplitude),\n",
        "        [] if self.length_scale is None else tf.shape(self.length_scale))\n",
        "\n",
        "  def _apply(self, x1, x2, example_ndims=0):\n",
        "    # x1, x2 shoule be #obs x 2\n",
        "    season1 = x1[:,0:]\n",
        "    week1 = x1[:,1:] \n",
        "    season2 = x2[:,0:]\n",
        "    week2 = x2[:,1:]\n",
        "\n",
        "    k = tfk.ExponentiatedQuadratic(self.amplitude[0], self.length_scale[0])\n",
        "    k._apply(week1,week2)\n",
        "\n",
        "    same_season = (season1 == season2)\n",
        "    ks = tfk.ExponentiatedQuadratic(self.amplitude[1], self.length_scale[1])\n",
        "    ks._apply(week1[same_season, 1:],week2[same_season, 1:])\n",
        "\n",
        "    if (season1 != season2):\n",
        "      return k\n",
        "    else:\n",
        "      return k+ks\n",
        "\n",
        "  def _parameter_control_dependencies(self, is_init):\n",
        "    if not self.validate_args:\n",
        "      return []\n",
        "    assertions = []\n",
        "    for arg_name, arg in dict(amplitude=self.amplitude,\n",
        "                              length_scale=self.length_scale).items():\n",
        "      if arg is not None and is_init != tensor_util.is_ref(arg):\n",
        "        assertions.append(assert_util.assert_positive(\n",
        "            arg,\n",
        "            message='{} must be positive.'.format(arg_name)))\n",
        "    return assertions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL_iZdwi362g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kk9Zb1GQ08V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = f.constant([5, 4, 6])\n",
        "\n",
        "season1 = x1[,0]\n",
        "week1 = x1[,1]\n",
        "season2 = x2[,0]\n",
        "week2 = x2[,1]\n",
        "\n",
        "\n",
        "\n",
        "k = tfk.ExponentiatedQuadratic(self.length_scale[0], self.length_scale[0])\n",
        "k._apply(week1,week2)\n",
        "\n",
        "same_season = (season1 == season2)\n",
        "ks = tfk.ExponentiatedQuadratic(self.length_scale[1], self.length_scale[1])\n",
        "ks._apply(week1[same_season, :],week2[same_season, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI23pNxH4FdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "tfb = tfp.bijectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGw9p2ZM37w_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "e8d983dd-e169-4678-c485-10870d7de94a"
      },
      "source": [
        "amplitude_var = tfp.util.TransformedVariable(\n",
        "    initial_value=1.,\n",
        "    bijector=constrain_positive,\n",
        "    name='amplitude',\n",
        "    dtype=np.float64)\n",
        "\n",
        "length_scale_var = tfp.util.TransformedVariable(\n",
        "    initial_value=1.,\n",
        "    bijector=constrain_positive,\n",
        "    name='length_scale',\n",
        "    dtype=np.float64)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1ff5da9e4aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m amplitude_var = tfp.util.TransformedVariable(\n\u001b[1;32m      2\u001b[0m     \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbijector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstrain_positive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'amplitude'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     dtype=np.float64)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'constrain_positive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYjJUe3j4N4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36e5e3a1-4c95-4224-a3c3-e7881d197906"
      },
      "source": [
        "amplitude"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tfp.distributions.LogNormal 'LogNormal' batch_shape=[] event_shape=[] dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA_BWtIz3jTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2eb918d1-70fa-432e-d014-5e565b8b1088"
      },
      "source": [
        "# Suppose `SomeKernel` acts on vectors (rank-1 tensors)\n",
        "test = season_week_kernel(amplitude,length_scale)\n",
        "test.batch_shape\n",
        "# ==> []\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2c8c7159df8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseason_week_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ==> []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-31b312c89224>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, amplitude, length_scale, feature_ndims, validate_args, name)\u001b[0m\n\u001b[1;32m     39\u001b[0m           [amplitude, length_scale])\n\u001b[1;32m     40\u001b[0m       self._amplitude = tensor_util.convert_nonref_to_tensor(\n\u001b[0;32m---> 41\u001b[0;31m           amplitude, name='amplitude', dtype=dtype)\n\u001b[0m\u001b[1;32m     42\u001b[0m       self._length_scale = tensor_util.convert_nonref_to_tensor(\n\u001b[1;32m     43\u001b[0m           length_scale, name='length_scale', dtype=dtype)\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_probability/python/internal/tensor_util.py\u001b[0m in \u001b[0;36mconvert_nonref_to_tensor\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   return tf.convert_to_tensor(\n\u001b[0;32m--> 115\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'LogNormal' has no len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MObbw9e4Wpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# `x` and `y` are batches of five 3-D vectors:\n",
        "x = np.ones([5, 3], np.float32)\n",
        "y = np.ones([5, 3], np.float32)\n",
        "scalar_kernel.apply(x, y).shape\n",
        "# ==> [5]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}