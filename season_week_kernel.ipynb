{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "season-week-kernel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLGpxq59O9TdTlOrdiC4yu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Serena-Wang/Anagrams/blob/master/season_week_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsoiI0UCfjo8",
        "colab_type": "code",
        "outputId": "138b60db-66d7-46a7-e66c-53e5c65dce61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/probability.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'probability'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 31388 (delta 77), reused 64 (delta 7), pack-reused 31251\u001b[K\n",
            "Receiving objects: 100% (31388/31388), 51.60 MiB | 26.39 MiB/s, done.\n",
            "Resolving deltas: 100% (26187/26187), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ_T5cGif2qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/probability')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "751IhCK6gm9S",
        "colab_type": "code",
        "outputId": "a6e467c9-ccc3-4fa4-c6a6-8b67abf2dd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/probability/tensorflow_probability"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/probability/tensorflow_probability\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSvsXAnhFvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1t_aM7BgBw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import probability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKUhonOMbuzv",
        "colab_type": "code",
        "outputId": "ba796efb-15e5-4306-be74-03812ff3a002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from tensorflow_probability.python.internal import assert_util\n",
        "from tensorflow_probability.python.internal import tensor_util\n",
        "from tensorflow_probability.python.math.psd_kernels.internal import util\n",
        "from tensorflow_probability.python.math.psd_kernels import exponentiated_quadratic\n",
        "from tensorflow_probability.python.math.psd_kernels.positive_semidefinite_kernel import PositiveSemidefiniteKernel\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az48uq5KcrZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__all__ = ['season_week_kernel']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq2sCy8tja08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class season_week_kernel(PositiveSemidefiniteKernel):\n",
        "  \"\"\"The season_week_kernel kernel.\n",
        "  Sometimes called the \"squared exponential\", \"Gaussian\" or \"radial basis\n",
        "  function\", this kernel function has the form\n",
        "    ```none\n",
        "    k(x, y) = amplitude**2 * exp(-||x - y||**2 / (2 * length_scale**2))\n",
        "    ```\n",
        "  where the double-bars represent vector length (ie, Euclidean, or L2 norm).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               amplitude_k=None,\n",
        "               length_scale_k=None,\n",
        "               amplitude_ks=None,\n",
        "               length_scale_ks=None,\n",
        "               feature_ndims=1,\n",
        "               validate_args=False,\n",
        "               name='season_week_kernel'):\n",
        "    \"\"\"Construct an ExponentiatedQuadratic kernel instance.\n",
        "    Args:\n",
        "      amplitude: floating point `Tensor` that controls the maximum value\n",
        "        of the kernel. Must be broadcastable with `length_scale` and inputs to\n",
        "        `apply` and `matrix` methods. Must be greater than zero. A value of\n",
        "        `None` is treated like 1.\n",
        "        Default value: None\n",
        "      length_scale: floating point `Tensor` that controls how sharp or wide the\n",
        "        kernel shape is. This provides a characteristic \"unit\" of length against\n",
        "        which `||x - y||` can be compared for scale. Must be broadcastable with\n",
        "        `amplitude` and inputs to `apply` and `matrix` methods. A value of\n",
        "        `None` is treated like 1.\n",
        "        Default value: None\n",
        "      feature_ndims: Python `int` number of rightmost dims to include in the\n",
        "        squared difference norm in the exponential.\n",
        "      validate_args: If `True`, parameters are checked for validity despite\n",
        "        possibly degrading runtime performance\n",
        "      name: Python `str` name prefixed to Ops created by this class.\n",
        "    \"\"\"\n",
        "    parameters = dict(locals())\n",
        "    with tf.name_scope(name):\n",
        "      dtype = util.maybe_get_common_dtype(\n",
        "          [amplitude_k,amplitude_ks, length_scale_k, length_scale_ks])\n",
        "      self._amplitude_k = tensor_util.convert_nonref_to_tensor(\n",
        "          amplitude_k, name='amplitude_k', dtype=dtype)\n",
        "      self._amplitude_ks = tensor_util.convert_nonref_to_tensor(\n",
        "          amplitude_ks, name='amplitude_k', dtype=dtype)\n",
        "      self._length_scale_k = tensor_util.convert_nonref_to_tensor(\n",
        "          length_scale_k, name='length_scale_ks', dtype=dtype)\n",
        "      self._length_scale_ks = tensor_util.convert_nonref_to_tensor(\n",
        "          length_scale_ks, name='length_scale_ks', dtype=dtype)\n",
        "      \n",
        "      super(season_week_kernel, self).__init__(\n",
        "          feature_ndims,\n",
        "          dtype=dtype,\n",
        "          name=name,\n",
        "          validate_args=validate_args,\n",
        "          parameters=parameters)\n",
        "\n",
        "  @property\n",
        "  def amplitude_k(self):\n",
        "    \"\"\"Amplitude parameter.\"\"\"\n",
        "    return self._amplitude_k\n",
        "\n",
        "  @property\n",
        "  def amplitude_ks(self):\n",
        "      \"\"\"Amplitude parameter.\"\"\"\n",
        "      return self._amplitude_ks\n",
        "\n",
        "  @property\n",
        "  def length_scale_k(self):\n",
        "    \"\"\"Length scale parameter.\"\"\"\n",
        "    return self._length_scale_k\n",
        "  \n",
        "  @property\n",
        "  def length_scale_ks(self):\n",
        "    \"\"\"Length scale parameter.\"\"\"\n",
        "    return self._length_scale_ks\n",
        "\n",
        "  ###not sure\n",
        "  ##This property describes the fully broadcast shape of all kernel parameters\n",
        "  def _batch_shape(self):\n",
        "    scalar_shape = tf.TensorShape([])\n",
        "    return tf.broadcast_static_shape(\n",
        "        tf.broadcast_static_shape(\n",
        "          tf.broadcast_static_shape(\n",
        "            scalar_shape if self.amplitude_k is None else self.amplitude_k.shape,\n",
        "            scalar_shape if self.length_scale_k is None else self.length_scale_k.shape),\n",
        "          scalar_shape if self.amplitude_ks is None else self.amplitude_ks.shape),\n",
        "        scalar_shape if self.length_scale_ks is None else self.length_scale_ks.shape)\n",
        "        \n",
        "  ###not sure\n",
        "  def _batch_shape_tensor(self):\n",
        "    return tf.broadcast_dynamic_shape(\n",
        "        tf.broadcast_dynamic_shape(\n",
        "          tf.broadcast_dynamic_shape(\n",
        "            [] if self.amplitude_k is None else tf.shape(self.amplitude_k),\n",
        "            [] if self.length_scale_k is None else tf.shape(self.length_scale_k)),\n",
        "          [] if self.amplitude_ks is None else tf.shape(self.amplitude_ks),\n",
        "        [] if self.length_scale_ks is None else tf.shape(self.length_scale_ks)))\n",
        "\n",
        "  def _apply(self, x1, x2, example_ndims=0):\n",
        "\n",
        "    if self.amplitude_k is not None:\n",
        "      amplitude_k = tf.convert_to_tensor(self.amplitude_k)\n",
        "      amplitude_k = util.pad_shape_with_ones(amplitude_k, example_ndims)\n",
        "\n",
        "    if self.length_scale_k is not None:\n",
        "      length_scale_k = tf.convert_to_tensor(self.length_scale_k)\n",
        "      length_scale_k = util.pad_shape_with_ones(length_scale_k, example_ndims)\n",
        "      \n",
        "    if self.amplitude_ks is not None:\n",
        "      amplitude_ks = tf.convert_to_tensor(self._amplitude_ks)\n",
        "      amplitude_ks = util.pad_shape_with_ones(amplitude_ks, example_ndims)\n",
        "\n",
        "    if self.length_scale_ks is not None:\n",
        "      length_scale_ks = tf.convert_to_tensor(self._length_scale_ks)\n",
        "      length_scale_ks = util.pad_shape_with_ones(length_scale_ks, example_ndims)\n",
        "      \n",
        "\n",
        "    k = tfp.math.psd_kernels.ExponentiatedQuadratic(self.amplitude_k, self.length_scale_k)\n",
        "\n",
        "    k_s = tfp.math.psd_kernels.ExponentiatedQuadratic(self.amplitude_ks, self.length_scale_ks)\n",
        "\n",
        "    result = k.apply(x1[:,1:], x2[:,1:], example_ndims=1)\n",
        "    result_s = k_s.apply(x1[:,1:], x2[:,1:], example_ndims=1)\n",
        "    #get rows with same seasons\n",
        "    inds = tf.where(x1[:, 0] == x2[:, 0])\n",
        "\n",
        "    shape = result.get_shape() \n",
        "\n",
        "    print(\"batch shape = \" + str(self._batch_shape()))\n",
        "    print(inds)\n",
        "    print(result_s.get_shape())\n",
        "\n",
        "    delta = tf.SparseTensor(inds, tf.gather_nd(result_s, [inds, :]), shape)\n",
        "    #print(tf.sparse.to_dense(delta))\n",
        "    final_result = result + tf.sparse.to_dense(delta)\n",
        "    return final_result\n",
        "    #print(final_result)\n",
        "\n",
        "  def _parameter_control_dependencies(self, is_init):\n",
        "    if not self.validate_args:\n",
        "      return []\n",
        "    assertions = []\n",
        "    for arg_name, arg in dict(amplitude_k=self.amplitude_k,\n",
        "                              length_scale_k=self.length_scale_k,amplitude_ks=self.amplitude_ks,\n",
        "                              length_scale_ks=self.length_scale_ks).items():\n",
        "      if arg is not None and is_init != tensor_util.is_ref(arg):\n",
        "        assertions.append(assert_util.assert_positive(\n",
        "            arg,\n",
        "            message='{} must be positive.'.format(arg_name)))\n",
        "    return assertions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPsxwWQDBvrD",
        "colab_type": "text"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI23pNxH4FdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "tfb = tfp.bijectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyGynMDZATv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c8297bb7-02a3-4868-f5e5-8d53352b1d52"
      },
      "source": [
        "np.random.seed(84963)\n",
        "x = np.concatenate(\n",
        "  (np.array([0, 0, 0, 1, 1]).reshape((5, 1)), np.linspace(1, 5, 5).reshape((5, 1))),\n",
        "  axis = 1\n",
        ")\n",
        "y = np.concatenate(\n",
        "  (np.array([0, 1, 1, 1, 2]).reshape((5, 1)), np.linspace(1, 2, 5).reshape((5, 1))),\n",
        "  axis = 1\n",
        ")\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 2.]\n",
            " [0. 3.]\n",
            " [1. 4.]\n",
            " [1. 5.]]\n",
            "[[0.   1.  ]\n",
            " [1.   1.25]\n",
            " [1.   1.5 ]\n",
            " [1.   1.75]\n",
            " [2.   2.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmr7NIl8AqU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel = season_week_kernel(0.5,1.2,0.7,1.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3aotdsBJoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9302d04c-19c8-4c78-89cf-ec7019577fec"
      },
      "source": [
        "kernel.apply(x, y, example_ndims=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch shape = ()\n",
            "tf.Tensor(\n",
            "[[0]\n",
            " [3]], shape=(2, 1), dtype=int64)\n",
            "(5,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              "array([0.74      , 0.20564438, 0.11445834, 0.24719116, 0.01098423],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh4RE_t0MBfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "ef4f7fe9-6845-4717-db90-18efae68369b"
      },
      "source": [
        "kernel = season_week_kernel([0.5, 0.2],[1.2, 1.7],[0.7, 0.8],[1.7, 2.0])\n",
        "kernel.apply(x, y, example_ndims=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch shape = (2,)\n",
            "tf.Tensor(\n",
            "[[0]\n",
            " [3]], shape=(2, 1), dtype=int64)\n",
            "(2, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-8ae4fa5d53ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseason_week_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_probability/python/math/psd_kernels/positive_semidefinite_kernel.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, x1, x2, example_ndims, name)\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_probability/python/math/psd_kernels/positive_semidefinite_kernel.py\u001b[0m in \u001b[0;36m_call_apply\u001b[0;34m(self, x1, x2, example_ndims)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_ndims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_expand_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-4c88cf61aa34>\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, x1, x2, example_ndims)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;31m#print(tf.sparse.to_dense(delta))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather_nd_v2\u001b[0;34m(params, indices, batch_dims, name)\u001b[0m\n\u001b[1;32m   4434\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgather_nd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4436\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather_nd\u001b[0;34m(params, indices, name, batch_dims)\u001b[0m\n\u001b[1;32m   4426\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4427\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4428\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4429\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4430\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_gather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_nd\u001b[0;34m(params, indices, name)\u001b[0m\n\u001b[1;32m   3589\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1] = [3] does not index into param shape [2,5] [Op:GatherNd]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tNAUNRIMgni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}